---
layout: slides
---

## What problems are we trying to solve?

- Decomposition
  - "What is a 'project'?"
- Reproducibility
  - "How did I produce Figure 3?"
  - "How did *they* produce Figure 3?"
- Correctness
  - "Does the code do what it's supposed to?"
  - "It is getting the right answer?"

---

## When to create a project

- A dataset used by several groups in several ways
  - Has its own data collection and tidying scripts
- A one-of-a-kind analysis
  - Data subsets, Jupyter notebooks, generated PDFs
- A software package
  - With a tutorial, documentation, and sample data

---

## Four approaches

- One repository per publication
  - Only if datasets and tools are their own projects
- One per tool
  - Only if you are comfortable creating packages
- One per team
  - But teams change over time
- One per regular meeting

---

## Standard files

- Put these in the project's root directory
  - With or without a `.md` suffix
- `README`: brief description of project
- [`CITATION.cff`](https://citation-file-format.github.io/): how to cite this project
- `CONDUCT`: what are the requirements or boundaries for interaction in this project
  - Part of [governance](../governance/)
- `CONTRIBUTING`
  - How to set up for development, what goes where, governance, etc.
  - Particularly important for [newcomers](../newcomers/)

---

## License

- `LICENSE(.md)`: who can do what
- Use a permissive license for software
  - The [GPL](g#gpl)'s virality has proven to be unnecessary
- [MIT License](g#mit-license): anyone can do anything, you are not liable, they have to give you credit
- [Hippocratic License](g#hippocratic-license): all of the above plus do no harm
- *Do not write your own license*

---

## License

- Use [Creative Commons](g#cc) (CC) for data and publications
- [CC-0](g#cc-0): anyone can use it any way they like
  - Best for raw data
- [CC-BY](g#cc-by): must cite you as source
  - Make sure `CITATION` is up to date
- [CC-BY-NC](g#cc-by-nc): need your permission to use commercially
  - Makes institutions happy
- *Do not write your own license*

---

## Data manifests

- One per directory with one entry per file
- Machine-readable
  - [JSON](g#json) or [YAML](g#yaml)
- *Include the units*
- A script that checks manifests against files is a useful addition to your [CI](g#ci)

---

## Data manifests

```yaml
- path: javascript-counts.csv
  format: CSV
  who: "Greg Wilson <gvwilson@third-bit.com>"
  what: "Line lengths of JavaScript files in TidyBlocks"
  when: 2019-11-29
  fields:
  - name: FileID
    type: integer
    content: "foreign key to filename in javascript-filenames.csv"
  - name: Length
    type: integer
    content: "line length (characters)"
  - name: Count
    type: integer
    content: "number of times that line length was seen in that file"
```

---

## Noble's Rules

- Choose filenames for easy wildcard matching
  - Tab completion means you don't have to type them all

{% include figure src="./noble-high-level.png" alt="Noble's Rules (high level)" %}

---

## Noble's Rules

- One sub-directory for each report
- Rename `ajcs-yyyy` as needed when the publication year is known

{% include figure src="./noble-per-report.png" alt="Noble's Rules (per report)" %}

---

## Noble's Rules

- All runnable code together
  - `bin` is a Unix convention ("binary" meant "compiled program")

{% include figure src="./noble-bin-directory.png" alt="Noble's Rules (bin directory)" %}

---

## Noble's Rules

- Source for compiled programs
- `Makefile` puts compiled programs into `../bin`

{% include figure src="./noble-src-directory.png" alt="Noble's Rules (bin directory)" %}

---

## Noble's Rules

- Raw data

{% include figure src="./noble-raw-data.png" alt="Noble's Rules (raw data)" width="90%" %}

- Never modify raw data files

---

## Noble's Rules

- Generated data sets
  - Only save if regenerating is expensive
- Add `.gitignore` to `results` directory to ignore certain files

{% include figure src="./noble-generated-data.png" alt="Noble's Rules (generated data)" width="90%" %}

---

## Noble's Rules

- Web site
- Contents may be generated from multiple sources

{% include figure src="./noble-web-site.png" alt="Noble's Rules (web site)" %}

---

## [Build manager](g#build-manager)

- [Make](https://www.gnu.org/software/make/) has dozens of imitators, but none have achieved critical mass
  - Use [`targets`](https://books.ropensci.org/targets/) for R
  - Use [`snakemake`](https://snakemake.github.io/) for Python
- A depends on B depends on C depends on…
- If C changes, re-create B and *then* re-create A
- Don't re-create D unless E changes

{% include figure src="./dependencies.png" alt="Dependencies" %}

---

class: sidebar

## Automation and notebooks

- Notebooks designed for interactive operation
  - Linear sequence of steps, short execution times
- Build managers designed for batch operation
  - Complex interactions, possibly long execution times
- Use notebooks as steps in a build
- Don't yet have good tools to express complex dependencies in notebooks

---

## [Continuous integration](g#ci)

1. Contributor pushes to repository
1. GitHub notices a CI configuration file
1. Creates a fresh virtual machine
1. Clones a fresh copy of repository
1. Runs tests, creates website, etc.
1. Reports results
1. …all while you're making tea

---

## Continuous integration

- Never forgets to do it
- Never forgets to tell people what it did
- Never forgets what it did
- Can do things on operating systems or software versions that individual developers don't have
- Documents the workflow
  - A checklist that is constantly checked

---

## Bots

- Connect CI to a Slack channel
- Don't send email
  - That relies on people setting up good filtering
- Use tools like [Zapier](https://zapier.com/) or [If This Then That](https://ifttt.com/) for more complex workflows
  - Specialized graphical workflow tools for research have mostly failed to achieve critical mass

---

## Lint

- The original `lint` checked for common problems in C
  - "It's legal, but you shouldn't do it that way"
- Readable code contains fewer bugs
- Use [`pycodestyle`](https://pypi.org/project/pycodestyle/) for Python, [`lintr`](https://cran.r-project.org/web/packages/lintr/index.html) for R, etc.
- Perform these checks in continuous integration

---

## Coding style (before)

```python
def count(ln):
    s = ['a', 'A', 'the',
             'The', 'and']
    n = 0
    for i in range(len(ln)):
        line = ln[i]
        stuff = line.split()
        for word in stuff:
            # print(word)
            j = s.count(word)
            if (j > 0) == True:
                n = n + 1
    return n
import sys
lines = sys.stdin.readlines()
## print('number of lines', len(lines))
n = count(lines)
print('number', n)
```

---

## Coding style (after)

```python
import sys

STOPS = {'a', 'A', 'the', 'The', 'and'}

def count(reader):
    n = 0
    for line in reader:
        for word in line.split():
            if word in STOPS:
                n += 1
    return n

if __name__ == '__main__':
    n = count(sys.stdin)
    print('number', n)
```

---

## Code review

- <cite>Bacchelli2013</cite>: the most cost-effective way to ensure code quality
  - And to spread knowledge through a team
- <cite>Cohen2010</cite>: most of the benefit comes from the first reviewer in the first hour
  - <a href="https://rethought.se/research/modern-code-reviews/">Modern Code Reviews</a> summarizes a lot of studies
- <cite>Petre2014</cite>: effective code review of scientific software requires domain knowledge

---

## Defensive coding

- Assert early, assert often
- `assert(condition, message)`
  - "There are no NAs in the address column"
  - "All ages are between 0 and 130"
- Reduces distance between something going wrong and the problem being noticed
- Allows readers to check their mental model
- Forces author to think about what "right" actually means
- [Design by contract](g#design-by-contract) discussed [elsewhere](../design/)
  - Add assertions for results ([post-conditions](g#post-condition)) as well as inputs ([pre-conditions](g#pre-condition))

---

## Quality is hard

- Hard to know if you're getting the right answer when you don't know what the right answer is
- …or when you don't know how close is close enough
  - What we *can* test may not be representative
  - Cases simple enough to have closed-form solutions only exercise the easy paths through the code
- …or when answers depend on deep domain knowledge
  - Errors are often in parameters, not code
  - "Subtle, not complex"
- Focus on the process and hope it produces the right results

---

## Unit testing

- Packages should have [unit tests](g#unit-test)
- Use small synthetic datasets
  - Always record the [seed](g#rng-seed) for random number generation
- Run–inspect–record–perturb to create tests

---

## Coverage

- Use code coverage to detect untested lines or paths
  - [`covr`](https://cran.microsoft.com/web/packages/covr/index.html) for R, [`coverage.py`](https://pypi.org/project/coverage/) for Python
- Check that asserts actually assert
  - An alarm that doesn't go off is worse than none at all

---

## Profiling

- A [profiler](g#profiler) measures how much time is spent on each line (or in each function) of a program
- Create a set of [benchmarks](g#benchmark) to track speed over time
  - Like unit tests, but for performance rather than correctness

---

## Publishing

- Put open access versions on the web
  - Please use preprint servers like [arXiv](https://arxiv.org/) or [bioRxiv](https://www.biorxiv.org/) rather than (just) your own website
  - Because [paywalls](g#paywall) are the raised middle finger of academia and you might move
- Give every report a [DOI](g#doi)
  - [Zenodo](https://zenodo.org/) does this for free
- Give datasets and software releases DOIs as well
  - [GitHub-Zenodo](https://guides.github.com/activities/citable-code/) integration makes this easy

---

## Make yourself citable

- People change names, institutions, email addresses, genders, titles…
- Get an [ORCID](g#orcid) and include it in all publications

---

class: exercise

## Check style

1. Run a linting program on your existing software. How many problems does it report? How many do you agree with?
1. Add linting to your build system so that others can run it with a single command.

---

class: exercise

## How close is close enough?

1. Pick a recently reported result.
1. Have team members separately write down how different it would have to be to make them nervous. (They must each provide a specific number.)
1. Compare answers.

---

class: exercise

## What's your coverage?

1. What fraction of your existing code is there to check that the rest of it works correctly?
1. If you have unit tests, use a coverage tool to see what they don't currently check.
1. How many of your assertions are tested?

---

class: exercise

## How is your project currently organized?

1. What files go where?
1. Where and how are your datasets documented?
1. Who chose the project's license?
1. How is your project's website maintained?

---

class: exercise

## How do notebooks change things?

Noble's Rules were written before computational notebooks became widespread.

1. Does it make sense to put notebooks in the project's root directory rather than in sub-directories?
1. Where should saved figures go?

---

class: exercise

## What alternatives should you consider?

1. What is the biggest difference between [GitHub Actions](https://github.com/features/actions) and a service like [CircleCI](https://circleci.com/)?
1. Which would be a better choice for your project? Why?
1. How do you feel about making your project critically dependent on external services that can change without notice?

---

class: exercise

## How are you and your work identified?

1. Search for your reports online: how accurate and complete are the results?
1. Do it again in an anonymous browser tab: how much is now inaccessible?
1. Search for yourself online: how accurate and complete are the results?

---

class: exercise

## Check your own citations

1. Are your datasets and packages citable?
1. Do your own publications cite them?
1. Are your contributors citable and cited?
