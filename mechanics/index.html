---
layout: slides
---

## What problems are we trying to solve?

- Decomposition
  - "What is a 'project'?"
- Reproducibility
  - "How did I produce Figure 3?"
  - "How did *they* produce Figure 3?"
- Correctness
  - "Does the code do what it's supposed to?"
  - "It is getting the right answer?"

---

## When to create a project

- A dataset used by several groups in several ways
  - Has its own data collection and tidying scripts
- A one-of-a-kind analysis
  - Data subsets, Jupyter notebooks, generated PDFs
- A software package
  - With a tutorial, documentation, and sample data

---

## Four approaches

- One repository per publication
  - Only if datasets and tools are their own projects
- One per tool
  - Only if you are comfortable creating packages
- One per team
  - But teams change over time
- One per regular meeting

---

## Standard files

- Put these in the project's root directory
  - With or without a `.md` suffix
- `README`: brief description of project
- [`CITATION.cff`](https://citation-file-format.github.io/): how to cite this project
- `CONTRIBUTING`
  - How to set up for development
  - What goes where
  - Governance
  - Particularly important for [newcomers](../newcomers/)

---

## License

- `LICENSE(.md)`: who can do what
- Use a permissive license for software
  - The [GPL](g#gpl)'s virality has proven to be unnecessary
- [MIT License](g#mit-license): anyone can do anything, you are not liable, they have to give you credit
- [Hippocratic License](g#hippocratic-license): all of the above plus do no harm
- *Do not write your own license*

---

## License

- Use [Creative Commons](g#cc) (CC) for data and publications
- [CC-0](g#cc-0): anyone can use it any way they like
  - Best for raw data
- [CC-BY](g#cc-by): must cite you as source
  - Make sure `CITATION` is up to date
- [CC-BY-NC](g#cc-by-nc): need your permission to use commercially
  - Makes institutions happy
- *Do not write your own license*

---

## Data manifests

- One per directory with one entry per file
- Machine-readable
  - [JSON](g#json) or [YAML](g#yaml)
- Include the units

---

## Data manifests

```yaml
- path: javascript-counts.csv
  format: CSV
  who: "Greg Wilson <gvwilson@third-bit.com>"
  what: "Line lengths of JavaScript files in TidyBlocks"
  when: 2019-11-29
  fields:
  - name: FileID
    type: integer
    content: "foreign key to filename in javascript-filenames.csv"
  - name: Length
    type: integer
    content: "line length (characters)"
  - name: Count
    type: integer
    content: "number of times that line length was seen in that file"
```

---

class: action

## Actions

- Choose licenses
  - Check with your institution
- Update `CITATION.cff` after each publication
- Check manifests against actual datasets
  - A script that checks [Markdown](g#markdown) headings against filenames is a useful addition to your [CI](g#ci)
- Decide which results need to be in version control and which can be regenerated
- Add `.gitignore` to `results` directory to ignore certain files

---

## Code of Conduct

- `CONDUCT(.md)`: how are participants expected to behave
- Signals that you want everyone to feel welcome
- Prevents people saying "but you didn't tell me"
- Spell out the complaint and enforcement process
  - Rules mean nothing if no one knows how to apply them
- Use the [Contributor Covenant](https://www.contributor-covenant.org/)

---

class: action

## Actions

- Choose a license
  - If your institution hasn't mandated one
- Review `README` and `CONTRIBUTING` quarterly
  - If your project has a calendar, add an entry
- Add to `CITATION` after each publication
- Define enforcement for `CONDUCT`

---

## Noble's Rules

- Choose filenames for easy wildcard matching
  - Tab completion means you don't have to type them all

{% include figure src="./noble-high-level.png" alt="Noble's Rules (high level)" %}

---

## Noble's Rules

- One sub-directory for each report
- Rename `ajcs-yyyy` as needed when the publication year is known

{% include figure src="./noble-per-report.png" alt="Noble's Rules (per report)" %}

---

## Noble's Rules

- All runnable code together
  - `bin` is a Unix convention ("binary" meant "compiled program")

{% include figure src="./noble-bin-directory.png" alt="Noble's Rules (bin directory)" %}

---

## Noble's Rules

- Source for compiled programs
- `Makefile` puts compiled programs into `../bin`

{% include figure src="./noble-src-directory.png" alt="Noble's Rules (bin directory)" %}

---

## Noble's Rules

- Raw data
  - Don't modify

{% include figure src="./noble-raw-data.png" alt="Noble's Rules (raw data)" width="90%" %}

---

## Noble's Rules

- Generated data sets
  - Only save if regenerating is expensive

{% include figure src="./noble-generated-data.png" alt="Noble's Rules (generated data)" width="90%" %}

---

## Noble's Rules

- Web site
- Contents may be generated from multiple sources

{% include figure src="./noble-web-site.png" alt="Noble's Rules (web site)" %}

---

class: action

## Actions

- Decide which results need to be in version control and which can be regenerated
- Add `.gitignore` in root or to `results` to ignore certain files

---

class: action

## Actions

- Choose a theme for your website
  - Don't create one
- Fill in the first few pages
- Set a calendar entry to check it quarterly
  - You are using the project's calendar, right?

---

## Make and its children

- [Make](https://www.gnu.org/software/make/) was created in 1975 by a summer intern to recompile C programs
  - "If these files are out of date, re-create them"
- Dozens of imitators, but none have achieved critical mass
  - Use [`targets`](https://books.ropensci.org/targets/) for R
  - Use [`snakemake`](https://snakemake.github.io/) for Python

---

## Dependencies

- A depends on B
- B depends on C
- So if C changes:
  - Re-create B
  - Then re-create A
- Don't re-create D unless E changes

{% include figure src="./dependencies.png" alt="Dependencies" %}

---

class: sidebar

## Automation and notebooks

- Notebooks designed for interactive operation
  - Linear sequence of steps, short execution times
- Build managers designed for batch operation
  - Complex interactions, possibly long execution times
- Use notebooks as steps in a build
- Don't yet have good tools to express complex dependencies in notebooks

---

class: action

## Actions

- Make sure all repeated actions are in the build file
- Make sure they are documented in the build file
  - Because otherwise the docs will fall out of date
- Teach newcomers how to use the build system
  - Probably new to most of them
- Decide what should be in notebooks vs. packages

---

## [Continuous integration](g#ci)

1. Contributor pushes to repository
1. GitHub notices a CI configuration file
1. Creates a fresh virtual machine
1. Clones a fresh copy of repository
1. Runs tests, creates website, etc.
1. Reports results
1. â€¦all while you're making tea

---

## Continuous integration

- Never forgets to do it
- Never forgets to tell people what it did
- Never forgets what it did
- Can do things on operating systems or software versions that individual developers don't have
- Documents the workflow
  - A checklist that is constantly checked

---

## Bots

- Connect CI to a Slack channel
- Don't send email
  - That relies on people setting up good filtering
- Use tools like [Zapier](https://zapier.com/) or [If This Then That](https://ifttt.com/) for more complex workflows
  - Specialized graphical workflow tools for research have mostly failed to achieve critical mass

---

## Quality is hard

- Hard to know if you're getting the right answer when you don't know what the right answer is
- Harder when you don't know how close is close enough
  - The parts we *can* test may not be representative of the whole
  - Cases simple enough to have closed-form solutions only exercise the easy paths through the code
- Harder still when the answers depend on deep domain knowledge
  - Errors are often in parameters, not code
  - "Subtle, not complex"
- Focus on the process and hope it produces the right results

---

## Coding style (before)

```python
def count(ln):
    s = ['a', 'A', 'the',
             'The', 'and']
    n = 0
    for i in range(len(ln)):
        line = ln[i]
        stuff = line.split()
        for word in stuff:
            # print(word)
            j = s.count(word)
            if (j > 0) == True:
                n = n + 1
    return n
import sys
lines = sys.stdin.readlines()
## print('number of lines', len(lines))
n = count(lines)
print('number', n)
```

---

## Coding style (after)

```python
import sys

STOPS = {'a', 'A', 'the', 'The', 'and'}

def count(reader):
    n = 0
    for line in reader:
        for word in line.split():
            if word in STOPS:
                n += 1
    return n

if __name__ == '__main__':
    n = count(sys.stdin)
    print('number', n)
```

---

## Lint

- The original `lint` checked for common problems in C
  - "It's legal, but you shouldn't do it that way"
- Readable code contains fewer bugs
- Use [`pycodestyle`](https://pypi.org/project/pycodestyle/) for Python, [`lintr`](https://cran.r-project.org/web/packages/lintr/index.html) for R, etc.
- Perform these checks in continuous integration

---

class: action

## Actions

- Add linting to continuous integration checks
- Use default settings
  - Will save many hours of argument
  - And reduce unfamiliarity for newcomers
- Show people how to run checks before submitting PRs

---

## Code review

- <cite>Bacchelli2013</cite>: the most cost-effective way to ensure code quality
  - And to spread knowledge through a team
- <cite>Cohen2010</cite>: most of the benefit comes from the first reviewer in the first hour
  - <a href="https://rethought.se/research/modern-code-reviews/">Modern Code Reviews</a> summarizes a lot of studies
- <cite>Petre2014</cite>: effective code review of scientific software requires domain knowledge

---

class: action

## Actions

- Create a short checklist to guide newcomers
  - No more than a dozen points
  - Intended for them to outgrow
- Review first contributions promptly and warmly
  - Increases the chances that they'll become [regular contributors](../newcomers/)

---

## Defensive coding

- Assert early, assert often
- `assert(condition, message)`
  - "There are no NAs in the address column"
  - "All ages are between 0 and 130"
- Reduces distance between something going wrong and the problem being noticed
- Allows readers to check their mental model
- Forces author to think about what "right" actually means

---

## Unit testing

- Packages should have [unit tests](g#unit-test)
- Use small synthetic datasets
  - Always record the [seed](g#rng-seed) for random number generation
- Runâ€“inspectâ€“recordâ€“perturb
- Use code coverage to detect untested lines or paths
  - [`covr`](https://cran.microsoft.com/web/packages/covr/index.html) for R, [`coverage.py`](https://pypi.org/project/coverage/) for Python
- Check that asserts actually assert
  - An alarm that doesn't go off is worse than none at all

---

## This seems like a lot of work

- It actually saves time
  - Improving quality increases efficiency
  - In fact, it's the only thing that does
- And it takes less time than retracting a paper
  - Or reading a pull request that breaks something

---

## Publishing

- Put open access versions on the web
  - Preprint servers like arxiv.org or your own website
  - Because [paywalls](g#paywall) are the raised middle finger of academia
- Give every report a [DOI](g#doi)
  - [Zenodo](https://zenodo.org/) does this for free
- Give datasets and software releases DOIs as well
  - GitHub-Zenodo integration makes this easy

---

## Make yourself citable

- People change names, institutions, email addresses, genders, titlesâ€¦
- Get an [ORCID](g#orcid) and include it in all publications

---

class: action

## Actions

- Get DOIs for all publications, datasets, and packages
  Make sure they're included in `CITATION`
- Ask all new contributors for ORCIDs
- Submit reports to preprint servers
  - Better yet, publish in open access journals

---

class: exercise

## Check style

1. Run a linting program on your existing software. How many problems does it report? How many do you agree with?
1. Add linting to your build system so that others can run it with a single command.

---

class: exercise

## How close is close enough?

1. Pick a recently reported result.
1. Have team members separately write down how different it would have to be to make them nervous. (They must each provide a specific number.)
1. Compare answers.

---

class: exercise

## What's your coverage?

1. What fraction of your existing code is there to check that the rest of it works correctly?
1. If you have unit tests, use a coverage tool to see what they don't currently check.
1. How many of your assertions are tested?

---

class: exercise

## How is your project currently organized?

1. What files go where?
1. Where and how are your datasets documented?
1. Who chose the project's license?
1. How is your project's website maintained?

---

class: exercise

## How do notebooks change things?

Noble's Rules were written before computational notebooks became widespread.

1. Does it make sense to put notebooks in the project's root directory rather than in sub-directories?
1. Where should saved figures go?

---

class: exercise

## What alternatives should you consider?

1. What is the biggest difference between [GitHub Actions](https://github.com/features/actions) and a service like [CircleCI](https://circleci.com/)?
1. Which would be a better choice for your project? Why?
1. How do you feel about making your project critically dependent on external services that can change without notice?

---

class: exercise

## How are you and your work identified?

1. Search for your reports online: how accurate and complete are the results?
1. Do it again in an anonymous browser tab: how much is now inaccessible?
1. Search for yourself online: how accurate and complete are the results?

---

class: exercise

## Check your own citations

1. Are your datasets and packages citable?
1. Do your own publications cite them?
1. Are your contributors citable and cited?
